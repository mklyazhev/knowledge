https://eldf.ru/machine-learning-base-article
# Виды обучения

![[Pasted image 20240608232733.png]]
# Виды задач

![[Pasted image 20240608233325.png]]
# Виды моделей

## Линейные модели
### Линрег
### Логрег
### SVM
## Метрические модели
### K-NN (K-ближайшие соседи)
### K-Means
## Решающие деревья
## Ансамбли
### Стекинг

Метод ансамблевого обучения, в котором несколько моделей (базовых моделей) обучаются на одном и том же наборе данных, а их предсказания используются в качестве входных данных для метамодели, которая обучается объединять эти предсказания для улучшения итогового результата.
### Бэггинг

Идея заключается в создании нескольких моделей с использованием разных подвыборок данных и последующем объединении их предсказаний.
### Случайный лес

Алгоритм основан на ансамбле решений, которые объединяют множество деревьев решений для получения более точных и устойчивых предсказаний.
#### Основные концепции случайного леса

1. **Ансамблирование (Ensembling):**
    
    - Ансамблирование — это метод, при котором несколько моделей объединяются для улучшения общей производительности модели.
2. **Бэггинг (Bagging):**
    
    - Бэггинг (Bootstrap Aggregating) — это метод, который использует несколько подвыборок тренировочных данных (с повторением) для обучения каждого дерева решений.
    - Каждое дерево обучается на своей подвыборке данных, а затем их предсказания объединяются (например, с помощью голосования для классификации или усреднения для регрессии).
3. **Случайное подмножество признаков:**
    
    - При построении каждого дерева случайный лес выбирает случайное подмножество признаков для рассмотрения при каждом разбиении. Это добавляет дополнительную случайность и помогает уменьшить корреляцию между деревьями.

Нужны глубокие деревья.
### Бустинг

Метод ансамблевого обучения, который объединяет несколько слабых моделей, обучаемых последовательно, где каждая новая модель корректирует ошибки, допущенные предыдущими моделями.
### Градиентный бустинг

Алгоритм объединяет множество слабых моделей в одну сильную модель. Основная идея заключается в последовательном обучении моделей, каждая из которых пытается скорректировать ошибки своих предшественников.
#### Основные концепции градиентного бустинга

1. **Ансамблирование (Ensembling):**
    
    - Ансамблирование — это метод, при котором несколько моделей объединяются для улучшения общей производительности.
2. **Бустинг (Boosting):**
    
    - Бустинг — это метод ансамблирования, при котором модели обучаются последовательно. Каждая новая модель пытается исправить ошибки, сделанные предыдущими моделями.
3. **Градиентный спуск (Gradient Descent):**
    
    - Градиентный спуск — это метод оптимизации, который используется для минимизации функции потерь. В градиентном бустинге ошибки моделей корректируются с помощью градиентного спуска.

Нужны неглубокие деревья.
## Нейронные сети
## PCA
## SVD
# Виды метрик
## Классификация
### Accuracy (доля правильных ответов)
### Precision (точность)
### Recall (полнота)
### F-score
### AUC-ROC
### AUC-PR
## Регрессия
### MSE
### MAE
### MLE
# Виды функций потерь
## Cross-Entropy Loss
## MSE
## MAE
# Регуляризация

Регуляризация — это метод, используемый в машинном обучении для предотвращения переобучения модели.
### Основные методы регуляризации

1. **L1-регуляризация (Lasso-регуляризация):**
    
    - Добавляет сумму абсолютных значений коэффициентов (весов) модели к функции потерь.
    - Цель — минимизировать как ошибку на тренировочных данных, так и эту сумму.
    - Способствует разреженности модели, то есть многие коэффициенты становятся равными нулю, что приводит к более простой и интерпретируемой модели.
    - Формула: $\text{Loss} = MSE + \lambda \sum |w_{i}|$
2. **L2-регуляризация (Ridge-регуляризация):**
    
    - Добавляет сумму квадратов коэффициентов к функции потерь.
    - Цель — минимизировать как ошибку на тренировочных данных, так и эту сумму квадратов.
    - Способствует уменьшению величины коэффициентов, что делает модель более устойчивой.
    - Формула: $\text{Loss} = MSE + \lambda \sum w_{i}^2$
3. **Elastic Net:**
    
    - Комбинирует L1 и L2 регуляризации.
    - Цель — воспользоваться преимуществами обоих методов.
    - Формула: $\text{Loss} = MSE + \lambda_{1} \sum |w_{i}| + \lambda_{2} \sum w_{i}^2$

Когда вы добавляете регуляризацию, вы изменяете функцию потерь, которую оптимизирует ваша модель. Вместо того чтобы минимизировать только ошибку предсказания (например, Mean Squared Error, MSE), вы минимизируете сумму ошибки предсказания и штрафа за сложность модели.
# A/B тесты

A/B тесты — это метод экспериментального сравнения двух версий чего-либо, чтобы выяснить, какая из них работает лучше.

Суть A/B тестов заключается в сравнении двух версий одной и той же вещи (например, веб-страницы) с одной единственной измененной характеристикой, чтобы понять, какая версия лучше выполняет заданную цель. Эти версии называются:
- **Версия A**: Это текущая версия (контрольная группа).
- **Версия B**: Это измененная версия (тестовая группа).

Процесс проведения A/B теста можно разделить на несколько шагов:
1. **Определение цели и гипотезы**:
    - **Цель**: Что вы хотите улучшить? Например, увеличить число регистраций на сайте.
    - **Гипотеза**: Какое изменение может помочь достичь этой цели? Например, добавление кнопки "Зарегистрироваться сейчас" может увеличить число регистраций.
2. **Создание версий**:
    - **Версия A (контрольная)**: Текущая версия веб-страницы или элемента.
    - **Версия B (тестовая)**: Модифицированная версия с изменением, которое вы хотите протестировать.
3. **Рандомизация и разделение трафика**:
    - Пользователи случайным образом распределяются между двумя версиями. Например, 50% пользователей видят версию A, а другие 50% — версию B.
4. **Сбор данных**:
    - На протяжении определенного времени собираются данные о взаимодействиях пользователей с каждой версией. Это могут быть клики, покупки, регистрации и т.д.
5. **Анализ результатов**:
    - Сравниваются показатели для каждой версии. Например, сколько пользователей зарегистрировались на версии A и сколько на версии B.
    - Используются статистические методы для проверки значимости различий. Это помогает понять, является ли разница между версиями значимой или случайной.
6. **Принятие решения**:
    - Если версия B показывает лучшие результаты, она может быть принята в качестве основной.
    - Если версия B не улучшает показатели или ухудшает их, остаётся версия A.

### Пример A/B теста

**Цель**: Увеличить количество кликов на кнопку "Купить сейчас".
**Гипотеза**: Изменение цвета кнопки с синего на красный увеличит количество кликов.
1. **Версия A**: Текущая страница с синей кнопкой.
2. **Версия B**: Измененная страница с красной кнопкой.
**Рандомизация**: Пользователи случайным образом видят одну из двух версий.
**Сбор данных**: В течение недели собираются данные о кликах на кнопку.
**Анализ результатов**:
- Версия A: 5% пользователей кликнули на синюю кнопку.
- Версия B: 6% пользователей кликнули на красную кнопку.
**Принятие решения**: Красная кнопка более эффективна, поэтому она будет внедрена на сайте.